{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: Extracting Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from openai import OpenAI  \n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "os.chdir(r'C:\\Users\\beperron\\Documents\\Projects\\demystifying-APIs')\n",
    "df = pd.read_excel(r'LBC_MetaData.xlsx').sample(10, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------#\n",
    "#     ChatGPT API             #\n",
    "#-----------------------------#\n",
    "\n",
    "# The base URL is include in the OpenAI function\n",
    "# Here is the base_url for reference\n",
    "# base_url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "load_dotenv()\n",
    "model = \"gpt-4o\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#-----------------------------#\n",
    "#     DeepSeek API            #\n",
    "#-----------------------------#\n",
    "\n",
    "load_dotenv()\n",
    "model = \"deepseek-chat\"\n",
    "openai_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "client = OpenAI(api_key=openai_api_key, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#-----------------------------#\n",
    "#     Groq API                #\n",
    "#-----------------------------#\n",
    "\n",
    "load_dotenv()\n",
    "model = \"llama3-8b-8192\"\n",
    "openai_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Groq(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_extraction_prompt = \"You are a helpful assistant with expertise in social work research and Chinese geography.\"\n",
    "\n",
    "user_extraction_prompt = \"\"\"\n",
    "Carefully read the following scientific abstract. Identify and extract any Chinese locations that are \n",
    "first-level administrative divisions under China's central government in mainland China. These include:\n",
    "\n",
    "- Provinces\n",
    "- Municipalities directly under the central government\n",
    "- Autonomous regions\n",
    "\n",
    "If a city or county is mentioned instead of a province or autonomous region, return the corresponding province, \n",
    "municipality, or autonomous region in English. For example, if '广州市' is mentioned, return 'Guangdong Province'. \n",
    "Only extract locations at this administrative level. If multiple locations are present in a single abstract, \n",
    "separate each location with a semicolon. Return NONE if no specific province, city, or administrative region is mentioned. \n",
    "\n",
    "For unspecified mentions (e.g., \"10 provinces\", \"several regions\", \"southwestern China\", \"western China\"), return 'NONE'.\n",
    "Do not make any assumptions or inferences about unspecified locations. Return NONE if no specific name mentioned, or need \n",
    "guess or infer any locations based on context or general knowledge.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract country names from the text using GPT-4o via OpenAI API\n",
    "def extract_location(abstract):\n",
    "           \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # Specify the model to use\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_extraction_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_extraction_prompt + abstract\n",
    "                \n",
    "            }\n",
    "        ],\n",
    "        temperature=0,  # Set response randomness (0 means deterministic responses)\n",
    "        max_tokens=2500,  # Set the maximum token length of the response\n",
    "        top_p=1,  # Use nucleus sampling (1 means only the most likely tokens are considered)\n",
    "        frequency_penalty=0,  # No penalty for frequent tokens\n",
    "        presence_penalty=0  # No penalty for new topic introduction\n",
    "    )\n",
    "    # Extract country names from the response\n",
    "    location = response.choices[0].message.content.strip()\n",
    "    return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function to the 'abstract' column and store the API response in a new column 'Location'\n",
    "df['Location'] = df['Abstract'].apply(extract_location)\n",
    "\n",
    "df.to_excel('LBC_Locations_Extracted.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
